{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification of simulated AT-TPC events\n",
    "\n",
    "Welcome to this project in applied machine learning. In this project we will tackle a simple classification problem of two different classes. The classes are  simulated reaction types for the Ar(p, p') experiment conducted at MSU, in this task we'll focus on the classification task and simply treat the experiment as a black box. \n",
    "\n",
    "### This is a completed notebook with solution examples, for your implementation we suggest you implement your own solution in the `project.ipynb` notebook\n",
    "\n",
    "This project has three tasks with a recommendation for the time to spend on each task: \n",
    "\n",
    "- Preparation, Data exploration and standardization: 0.5hr\n",
    "- Model construction: 1hr\n",
    "- Hyperparameter tuning and performance validation: 1hr\n",
    "\n",
    "There is a notebook `project_solution.ipynb` included with suggestions to solutions for each task included, for reference or to easily move on to a part of the project more appealing to your interests. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation: \n",
    "\n",
    "This project uses python and the machine learning library `keras`. As well as some functionality from `numpy` and `scikit-learn`. We recommend a `Python` verson of `>3.4`. These libraries should be installed to your specific system by using the command `pip3 install --user LIBRARY_NAME`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Data exploration and standardization \n",
    "\n",
    "In machine learning, as in many other fields, the task of preparing data for analysis is as vital as it can be troublesome and tedious. In data-analysis the researcher can expect to spend the majority of their time merely processing data to prepare for analysis. In this projcet we will focus more on the entire pipeline of analysis, and so the data at hand has already been shaped to an image format suitable for our analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1a: Loading the data\n",
    "\n",
    "The data is stored in the `.npy` format using vecotrized code to speed up the read process. The files pointed to in this task are downsampled images with dimensions $64 x 64$ (if the images are to big for your laptop to handle, the script included in `../scripts/downsample_images.py` can further reduce the dimension). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (8000, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # we'll be using this shorthand for the NumPy library throughout\n",
    "\n",
    "dataset = np.load(\"../data/images/project_data.npy\")\n",
    "n_samples = dataset.shape[0]\n",
    "\n",
    "print(\"Data shape: \", dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1b: Inspecting the data\n",
    "\n",
    "The data is stored as xy projections of the real events, who take place in a 3d volume. This allows a simple exploratiuon of the data as images. In this task you should plot a few different events in a grid using `matplotlib.pyplot` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rows = 2\n",
    "cols = 2\n",
    "n_plots = rows*cols\n",
    "fig, axs = plt.subplots(nrows=rows, ncols=cols, figsize=(10, 10 ))\n",
    "\n",
    "\n",
    "for row in axs: \n",
    "    for ax in row:\n",
    "        \"\"\"\n",
    "        one of pythons most wonderful attributes is that if an object is iterable it can be\n",
    "        directly iterated over, like above. \n",
    "        ax is an axis object from the 2d array of axis objects\n",
    "        \"\"\"\n",
    "\n",
    "        which = np.random.randint(0, n_samples)\n",
    "        ax.imshow(dataset[which].reshape(64, 64))\n",
    "        ax.axis(\"off\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1c: Standardizing the data\n",
    "An important part of the preprocessing of data is the standardization of the input. The intuition here is simply that the model should expect similar values in the input to mean the same. \n",
    "\n",
    "You should implement a standardization of the input. Perhaps the most common standardization is the centering of the mean of the distribution, and scaling by the standard deviation: \n",
    "\n",
    "$X_s = \\frac{X - \\mu}{\\sigma}$\n",
    "\n",
    "Note that for our data we only want to standardize the signal part of our image, we know the rest is zero and we don't want the standardization to be unduly effected. This also means we don't necessarily want a zero mean for our signal distribution. So for this example we stick with the scaling:\n",
    "\n",
    "$X_s = \\frac{X}{\\sigma}$\n",
    "\n",
    "Another important fact is that at already at this point is it recommended to separate the data in train and test sets. The partion of the data to test on should be roughly 10-20%. And to remember to compute the standardization variables only from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean:  1.1661787282024227\n",
      "Train Std.:  4.498873508156905\n",
      "-------------\n",
      "Test Mean:  1.105126519078845\n",
      "Test Std.:  4.20416144539155\n",
      "############\n",
      "Train Mean:  0.259215718354389\n",
      "Train Std.:  0.9999999999999997\n",
      "-------------\n",
      "Test Mean:  0.2456451636337721\n",
      "Test Std.:  0.934492031787288\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "targets = np.load(\"../data/targets/project_targets.npy\")\n",
    "train_X, test_X, train_y, test_y = train_test_split(dataset, targets, test_size=0.15)\n",
    "\n",
    "nonzero_indices = np.nonzero(train_X)\n",
    "nonzero_elements = train_X[nonzero_indices]\n",
    "\n",
    "print(\"Train Mean: \", nonzero_elements.mean())\n",
    "print(\"Train Std.: \", nonzero_elements.std())\n",
    "print(\"-------------\")\n",
    "print(\"Test Mean: \", test_X[np.nonzero(test_X)].mean())\n",
    "print(\"Test Std.: \", test_X[np.nonzero(test_X)].std())\n",
    "print(\"############\")\n",
    "\n",
    "nonzero_scaled = nonzero_elements/nonzero_elements.std()\n",
    "train_X[nonzero_indices] = nonzero_scaled\n",
    "test_X[np.nonzero(test_X)] /= nonzero_elements.std()\n",
    "\n",
    "print(\"Train Mean: \", nonzero_scaled.mean())\n",
    "print(\"Train Std.: \", nonzero_scaled.std())\n",
    "print(\"-------------\")\n",
    "print(\"Test Mean: \", test_X[np.nonzero(test_X)].mean())\n",
    "print(\"Test Std.: \", test_X[np.nonzero(test_X)].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We also want to plot up the data again to confirm that our scaling is sensible, you should reuse your code from above for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rows = 2\n",
    "cols = 2\n",
    "n_plots = rows*cols\n",
    "fig, axs = plt.subplots(nrows=rows, ncols=cols, figsize=(10, 10 ))\n",
    "\n",
    "\n",
    "for row in axs: \n",
    "    for ax in row:\n",
    "        \"\"\"\n",
    "        one of pythons most wonderful attributes is that if an object is iterable it can be\n",
    "        directly iterated over, like above. \n",
    "        ax is an axis object from the 2d array of axis objects\n",
    "        \"\"\"\n",
    "\n",
    "        which = np.random.randint(0, train_X.shape[0])\n",
    "        ax.imshow(train_X[which].reshape(64, 64))\n",
    "        ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1d: Encoding the targets: \n",
    "\n",
    "For classification one ordinarily encodes the target as a n-element zero vector with one element valued at 1 indicating the target class. This is simply called one-hot encoding.\n",
    "\n",
    "You should inspect the values of the target vectors and use the imported `OneHotEncoder` to convert the targets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a: Creating a model\n",
    "\n",
    "In this task we will create a CNN with fully connected bottom-layers for classification. You should base your code on Morten's code for a model. We suggest yo do one of the following for this task: \n",
    "\n",
    "1. Implement a class or function `cnn` that returns a compiled Keras model with an arbitrary number of convolutional and fully connected layers with optional configuration of regularization terms or layers.\n",
    "2. Implement a simple hard-coded function `cnn` that returns a Keras model object. The architecture should be specified in the function. \n",
    "\n",
    "Both implementations should include multiple convolutional layers and ending with a couple fully connected layers. The output of the network should be a softmax or log-softmax layer of logits.  \n",
    "\n",
    "You should experiment with where in the network you place the non-linearities and whether to use striding or pooling to reduce the input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "\n",
    "def create_convolutional_neural_network_keras(input_shape, receptive_field,\n",
    "                                              n_filters, n_neurons_connected, n_categories,\n",
    "                                              eta, lmbd):\n",
    "    \"\"\"\n",
    "    Modified from MH Jensen's course on machine learning in physics: \n",
    "    https://github.com/CompPhysics/MachineLearningMSU/blob/master/doc/pub/CNN/ipynb/CNN.ipynb\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(n_filters, (receptive_field, receptive_field), input_shape=input_shape, padding='same',\n",
    "              activation='relu', kernel_regularizer=l2(lmbd)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_neurons_connected, activation='relu', kernel_regularizer=l2(lmbd)))\n",
    "    model.add(Dense(n_categories, activation='softmax', kernel_regularizer=l2(lmbd)))\n",
    "    \n",
    "    sgd = SGD(lr=eta)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
